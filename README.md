# Описание проекта:
В группе компаний Газпром нефть существует портал “Система распространения знаний”, где каждый сотрудник компании может поделиться полезными материалами (книгами, статьями, извлеченными уроками и прочее). 

При добавлении материалов сотрудникам необходимо заполнить ряд полей карточки материала. Данная процедура требует большого количества времени. Поэтому предлагается в рамках решения данной задачи сэкономить время работы персонала и оптимизировать бизнес-процесс за счет частичной автоматизации. Необходимо, чтобы при добавлении материала система “сканировала документ” и определяла ключевые слова в нем.

# Задача:
1. Сократить время сотрудников на заполнение карточки документа, загружаемого в “Библиотеку знаний”;

2. Унифицировать теги к документам в “Библиотеке знаний”, за счет подбора ключевых слов из уже созданных путем сканирования списка уже созданных ключевых слов. При необходимости ключевые слова, определенные в документе, должны менять свою словоформу, чтобы не увеличивать список уже созданных ключевых слов.

# Формат выхода
xlsx-файл, содержащий топ-N слов (term) с наибольшей метрикой (value) и его наиболее весомые вариации (variants).

<p align="center">
  <img src="https://github.com/Donskoy-Andrey/sirius/blob/master/images/output.png" />
</p>

# Описание репозитория 
1. Папка **data**:\
**articles** - папка с исходными статьями, база данных\
**articles_txt** - статьи, преобразованные в txt формат скриптом\
**mydict** - папка с исходными словарями, база данных\
**mydict_txt** - словари, преобразованные в txt формат скриптом\
**test_folder** - файлы для проверки работы алгоритма и их преобразованный txt\
**clear_text.txt** - база данных, скомпанованная в 1 преобразованный файл\
**results.png** - результаты тестирования алгоритма\
**stopwords.txt** - стоп-слова (союзы, предлоги и другое, что не может быть ключевым словом)
2. **OCR.py** - скрипт запуска оптического распознавания символов (при нечитабельном pdf исходнике)
3. **check_file.py** - подсчет важных слов для файла
4. **data_transfering.py** - скрипт чтения и загрузки библиотеки
5. **script.py** - **основной скрипт**, запускающий подсчет важных слов статьи
6. **transrom_pdf.py** - конвертация библиотеки из pdf в txt
7. **txt_file_processing.py** - обработка txt результатов (приведение к изначальным морфемам, удаление мусора и ненужных символов)

![Результаты работы](https://github.com/Donskoy-Andrey/sirius/blob/master/images/results.png)

# Основные проблемы
1. Часто человек берет ключевые слова "из головы", то есть они не встречаются в тексте.
2. Обработка сборников текстов затруднительна ввиду наличия мусорных слов на каждой странице.
3. Иногда человек делает ключевым словом фразу из 5-6 слов, а алгоритм настроен максимум на 3 слова.
